{
  "hash": "cf2314f81ae25156fd9bb4d81335bb0b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Activity23\"\nformat: html\nwarning: false\nmessage: false\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Time Series Essentials, install if needed!\nlibrary(feasts)       # Feature extraction & decomposition\nlibrary(fable)        # Forecasting models (ARIMA, ETS, etc.)\nlibrary(fpp3)         # Tidy time series dataseta\nlibrary(astsa)        # Applied statistical TS methods from textbook\nlibrary(tseries)      # Unit root tests & TS diagnostics\nlibrary(tsibbledata)  # Curated TS datasets\nlibrary(quantmod)     # Financial data retrieval\nlibrary(tidyquant)    # Financial analysis in tidyverse\nlibrary(purrr)        # Functional programming for TS pipelines\nlibrary(readr)        # Efficient data import\n```\n:::\n\n\n## **1. SARIMA Model Structure**  \n\nA SARIMA$(p,d,q)(P,D,Q)_m$ model combines:  \n\n- **Regular components**: AR(p), MA(q) terms for short-term patterns  \n- **Seasonal components**: Seasonal AR(P), MA(Q) terms at period $m$  \n- **Differencing**: $d$ regular differences + $D$ seasonal differences  \n\n## **2. Strategic Differencing**  \n\n**Key Principle**: Use minimal differencing to stabilize mean/variance  \n\n::: {.cell}\n\n```{.r .cell-code}\n# AirPassengers dataset\nap_ts <- tsibble::as_tsibble(AirPassengers) %>% \n  index_by(Date = yearmonth(index)) %>% \n  rename(Passengers = value)\n\n# Automated selection\nap_ts %>% \n  features(Passengers, list(unitroot_kpss, unitroot_ndiffs, unitroot_nsdiffs))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 4\n  kpss_stat kpss_pvalue ndiffs nsdiffs\n      <dbl>       <dbl>  <int>   <int>\n1      2.98        0.01      1       0\n```\n\n\n:::\n\n```{.r .cell-code}\n# Visual check\nap_ts %>%\n  gg_tsdisplay(difference(log(Passengers), lag = 12))\n```\n\n::: {.cell-output-display}\n![](activity23_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n**Insight**: Seasonal differencing (lag=12) removes yearly patterns while preserving monthly trends  \n\n\n## **3. Model Building**  \n\n### **3.1 Candidate Models**  \n\n::: {.cell}\n\n```{.r .cell-code}\nmodels <- ap_ts %>%\n  model(\n    Auto = ARIMA(log(Passengers)),\n    Manual1 = ARIMA(log(Passengers) ~ pdq(1,1,1) + PDQ(0,1,1, period=12)),\n    Manual2 = ARIMA(log(Passengers) ~ pdq(2,1,0) + PDQ(1,1,0, period=12))\n  )\n\nglance(models) %>% arrange(AICc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 8\n  .model   sigma2 log_lik   AIC  AICc   BIC ar_roots   ma_roots  \n  <chr>     <dbl>   <dbl> <dbl> <dbl> <dbl> <list>     <list>    \n1 Auto    0.00132    250. -489. -489. -475. <cpl [2]>  <cpl [12]>\n2 Manual1 0.00137    245. -482. -482. -470. <cpl [1]>  <cpl [13]>\n3 Manual2 0.00148    241. -474. -473. -462. <cpl [14]> <cpl [0]> \n```\n\n\n:::\n:::\n\n### **3.2 Coefficient Check**  \n\nFor top model:  \n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_model <- models %>% \n  select(Auto)\n\ntidy(models) %>% \n  filter(.model == \"Auto\") \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 6\n  .model term     estimate std.error statistic  p.value\n  <chr>  <chr>       <dbl>     <dbl>     <dbl>    <dbl>\n1 Auto   ar1        0.575    0.0843       6.83 2.83e-10\n2 Auto   ar2        0.261    0.0842       3.11 2.33e- 3\n3 Auto   sma1      -0.555    0.0771      -7.21 3.99e-11\n4 Auto   constant   0.0193   0.00149     13.0  2.07e-25\n```\n\n\n:::\n:::\n\n\n## **4. Model Refinement Cycle**  \n\n1. Start with automatic differencing  \n2. Compare multiple model specifications  \n3. Validate residuals systematically  \n4. Iterate using PACF patterns  \n\n::: {.cell}\n\n```{.r .cell-code}\n# Final refinement example\nap_ts %>%\n  model(\n    Best = ARIMA(log(Passengers) ~ pdq(1,1,1) + PDQ(0,1,1, period=12))\n  ) %>% \n  report()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Passengers \nModel: ARIMA(1,1,1)(0,1,1)[12] \nTransformation: log(Passengers) \n\nCoefficients:\n         ar1      ma1     sma1\n      0.1960  -0.5784  -0.5643\ns.e.  0.2475   0.2132   0.0747\n\nsigma^2 estimated as 0.001375:  log likelihood=244.95\nAIC=-481.9   AICc=-481.58   BIC=-470.4\n```\n\n\n:::\n:::\n\n\n## **Lab Activity**\n\n## **1. Data Preparation**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fpp3)\naccidents <- as_tsibble(USAccDeaths) %>% \n  rename(Deaths = value) %>% \n  mutate(Month = yearmonth(index))\n```\n:::\n\n**Q1:** Examine the seasonal patterns using `gg_season()`. What type of seasonality dominates this series?  \n\n\n## **2. Model Specification**\n\nFit SARIMA(1,1,1)(0,1,1)₁₂ model with maximum likelihood estimation\n\n::: {.cell}\n\n```{.r .cell-code}\nsarima_fit <- accidents %>%\n  model(SARIMA = ARIMA(Deaths ~ pdq(1,1,1) + PDQ(0,1,1, period = 12),\n                      stepwise = FALSE, approximation = FALSE))\n```\n:::\n\n**Q2:** Interpret the model structure:  \n\na) What does the (1,1,1) non-seasonal component represent?  \n\nb) Why do we use PDQ(0,1,1) for seasonal terms?  \n\n\n\n## **3. Parameter Estimation**\n\n**Task:** Extract and interpret coefficients\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(sarima_fit) %>% \n  mutate(signif = ifelse(p.value < 0.05, \"***\", \"\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 7\n  .model term  estimate std.error statistic p.value signif\n  <chr>  <chr>    <dbl>     <dbl>     <dbl>   <dbl> <chr> \n1 SARIMA ar1     0.0979     0.311     0.315 0.754   \"\"    \n2 SARIMA ma1    -0.511      0.274    -1.87  0.0668  \"\"    \n3 SARIMA sma1   -0.544      0.178    -3.05  0.00344 \"***\" \n```\n\n\n:::\n:::\n\n**Q3:** Which coefficients are statistically significant (α=0.05)? What does the MA(1) coefficient suggest?  \n\n## **4. Residual Diagnostics**\n\n### **4.1 Visual Analysis**\n\n::: {.cell}\n\n```{.r .cell-code}\nsarima_fit %>% \n  augment() %>% \n  ACF(.innov) %>% \n  autoplot() +\n  geom_hline(yintercept = c(-1,1)*1.96/sqrt(nrow(accidents)), linetype=2)\n```\n\n::: {.cell-output-display}\n![](activity23_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n**Q4:** Do residuals show concerning autocorrelation patterns? Justify your answer.  \n\n### **4.2 Formal Tests**\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(sarima_fit) %>% \n  features(.innov, list(\n    LB_test = ~ljung_box(.x, lag=24, dof=4)\n  ))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .model LB_test_lb_stat LB_test_lb_pvalue\n  <chr>            <dbl>             <dbl>\n1 SARIMA            25.9             0.170\n```\n\n\n:::\n:::\n\n**Q5:** Interpret the Ljung-Box (LB) test results: \n\na) Can we maintain the white noise assumption? \n\n\n## **5. Model Validation**\n\n**Task:** Check specification robustness\n\n::: {.cell}\n\n```{.r .cell-code}\naccidents %>% \n  model(\n    SARIMA_CSS = ARIMA(Deaths ~ pdq(1,1,1) + PDQ(0,1,1), \n                      method = \"CSS-ML\"),\n    AutoSARIMA = ARIMA(Deaths)\n  ) %>% \n  glance()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 8\n  .model      sigma2 log_lik   AIC  AICc   BIC ar_roots  ma_roots  \n  <chr>        <dbl>   <dbl> <dbl> <dbl> <dbl> <list>    <list>    \n1 SARIMA_CSS 104809.   -425.  859.  860.  867. <cpl [1]> <cpl [13]>\n2 AutoSARIMA 102860.   -425.  857.  857.  863. <cpl [0]> <cpl [13]>\n```\n\n\n:::\n:::\n\n**Q6:** Compare AICc values across estimation methods. Does our original model remain preferred?  \n",
    "supporting": [
      "activity23_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}