{
  "hash": "595405bd2a647b4eb0583ee9ff09eed7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Activity9\"\nformat: html\nwarning: false\nmessage: false\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# Time Series Essentials, install if needed!\nlibrary(feasts)       # Feature extraction & decomposition\nlibrary(fable)        # Forecasting models (ARIMA, ETS, etc.)\nlibrary(fpp3)         # Tidy time series dataseta\nlibrary(astsa)        # Applied statistical TS methods from textbook\nlibrary(tseries)      # Unit root tests & TS diagnostics\nlibrary(tsibbledata)  # Curated TS datasets\nlibrary(quantmod)     # Financial data retrieval\nlibrary(tidyquant)    # Financial analysis in tidyverse\nlibrary(purrr)        # Functional programming for TS pipelines\nlibrary(readr)        # Efficient data import\n```\n:::\n\n\n\n# 1. Foundations of Time Series Regression\n\nWe often model a response $Y_t$ as a linear function of a predictor $X_t$:\n\n$$\n\\begin{align}\nY_t &= \\beta_0 + \\beta_1 X_t + \\varepsilon_t, \\\n\\hat{\\beta}_1 &= \\frac{\\sum (Y_t - \\bar{Y})(X_t - \\bar{X})}{\\sum (X_t - \\bar{X})^2}.\n\\end{align}\n$$\n\nWhere:\n\n- $Y_t$ is the response at time $t$.\n- $X_t$ is the predictor at time $t$.\n- $\\beta_0$ is the intercept.\n- $\\beta_1$ is the slope.\n- $\\varepsilon_t$ is the error term.\n\n## 1.1 Finance Example (Amazon vs. S&P 500)\n\n*Dataset:* `gafa_stock` (Amazon vs Market Index)  \n\n::: {.cell}\n\n```{.r .cell-code}\n# 1) Get S&P 500 data (adjust as needed for start dates):\nsp500 <- tq_get(\"^GSPC\", from = \"2018-01-01\", to = \"2019-12-31\") %>%\n  # Rename for consistency\n  select(date, sp500_close = adjusted)\n\n# 2) Use Amazon data from gafa_stock in fpp3:\namzn <- gafa_stock %>%\n filter(Symbol == \"AMZN\", Date >= \"2018-01-01\", Date <= \"2018-12-31\") %>%\n select(Date, amzn_close = Adj_Close)\n\n# 3) Join by date\namzn_sp <- amzn %>%\n  inner_join(sp500, by = c(\"Date\" = \"date\")) \n\n# Regression coefficients\namzn_sp %>% \n  model(TSLM(amzn_close ~ sp500_close)) %>% \n  tidy() %>% \n  knitr::kable(caption = \"Coefficients table\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Coefficients table\n\n|.model                         |term        |     estimate|   std.error| statistic| p.value|\n|:------------------------------|:-----------|------------:|-----------:|---------:|-------:|\n|TSLM(amzn_close ~ sp500_close) |(Intercept) | -1940.961149| 255.8360580| -7.586738|       0|\n|TSLM(amzn_close ~ sp500_close) |sp500_close |     1.304591|   0.0930976| 14.013160|       0|\n\n\n:::\n\n```{.r .cell-code}\n# 4) Quick visualization\n amzn_sp %>%\n  ggplot(aes(x = sp500_close, y = amzn_close)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(\n    title = \"Amazon Stock vs S&P 500\",\n    x = \"S&P 500 Adjusted Close\",\n    y = \"Amazon Adjusted Close\"\n  )\n```\n\n::: {.cell-output-display}\n![](activity9_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n**COVID Example (Mobility):**  \n\n*Dataset:* `oxcgrt` (Oxford COVID Policy Tracker)  \n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readr)\nurl <- \"https://github.com/OxCGRT/covid-policy-dataset/raw/main/data/OxCGRT_compact_national_v1.csv\"\noxcgrt <- read_csv(url)\n```\n:::\n\n\n- Model: $\\log(\\text{ConfirmedCases}_t) = \\beta_0 + \\beta_1\\text{ConfirmedDeaths}_t + \\varepsilon_t$  \n- Activity: Test $H_0: \\beta_1=0$ using $t = \\frac{\\hat{\\beta}_1}{SE(\\hat{\\beta}_1)}$  \n\n::: {.cell}\n\n```{.r .cell-code}\noxcgrt %>% \n  filter(CountryName == \"United States\") %>% \n  mutate(Date = lubridate::ymd(Date)) %>% \n  as_tsibble(index = Date) %>% \n  tidyr::drop_na(ConfirmedCases,ConfirmedDeaths ) %>% \n  model(TSLM(ConfirmedCases ~ ConfirmedDeaths)) %>% \n  tidy()  %>% \n  knitr::kable(caption = \"Coefficients table\")\n```\n\n::: {.cell-output-display}\n\n\nTable: Coefficients table\n\n|.model                                 |term            |      estimate|    std.error| statistic| p.value|\n|:--------------------------------------|:---------------|-------------:|------------:|---------:|-------:|\n|TSLM(ConfirmedCases ~ ConfirmedDeaths) |(Intercept)     | -1.054628e+07| 4.288403e+05| -24.59255|       0|\n|TSLM(ConfirmedCases ~ ConfirmedDeaths) |ConfirmedDeaths |  9.148213e+01| 6.202599e-01| 147.48998|       0|\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\noxdata <- oxcgrt %>% \n  filter(CountryName == \"United States\") %>% \n  mutate(Date = lubridate::ymd(Date)) %>% \n  as_tsibble(index = Date) \n  \n\noxdata %>% \n  ggplot(aes(x = ConfirmedCases, y = ConfirmedDeaths)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +\n  labs(\n    title = \"Confirmed Cases vs Confirmed Deaths\",\n    x = \"Confirmed Cases\",\n    y = \"Confirmed Deaths\"\n  )\n```\n\n::: {.cell-output-display}\n![](activity9_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n#  Using `oxdata` for further COVID anaysis\n\n## Lab Activity 1\n\n1. Filter the data to one country (e.g., 'United States').\n2. Create a new variable, `log_cases`, defined as $\\\\(\\log(1 + \\text{ConfirmedCases})\\\\)$. \n   (Adding 1 helps avoid $\\\\(\\log(0)\\\\).)$\n3. Fit a TSLM model relating `log_cases` to `C6M_Stay at home requirements`.\n4. Interpret the slope coefficient.\n\n<!--\n\n### Solution\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter & transform\nexercise1_data <- oxcgrt %>%\n  filter(CountryName == 'United States') %>%\n  mutate(\n    Date = ymd(Date),\n    log_cases = log(1 + ConfirmedCases)\n  ) %>%\n  as_tsibble(index = Date) %>%\n  drop_na(log_cases, `C6M_Stay at home requirements`)\n\n# Fit TSLM\nex1_model <- exercise1_data %>%\n  model(tslm_ex1 = TSLM(log_cases ~ `C6M_Stay at home requirements`))\n\n# Summaries\nex1_model %>% tidy(tslm_ex1) %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|.model   |term                            |  estimate| std.error| statistic| p.value|\n|:--------|:-------------------------------|---------:|---------:|---------:|-------:|\n|tslm_ex1 |(Intercept)                     | 14.976905| 0.2302570| 65.044305|   0e+00|\n|tslm_ex1 |`C6M_Stay at home requirements` |  0.917216| 0.1722268|  5.325628|   1e-07|\n\n\n:::\n\n```{.r .cell-code}\nex1_model %>% glance(tslm_ex1) %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|.model   | r_squared| adj_r_squared|   sigma2| statistic| p_value| df|   log_lik|      AIC|     AICc|      BIC|       CV| deviance| df.residual| rank|\n|:--------|---------:|-------------:|--------:|---------:|-------:|--:|---------:|--------:|--------:|--------:|--------:|--------:|-----------:|----:|\n|tslm_ex1 | 0.0252702|     0.0243792| 15.75292|  28.36231|   1e-07|  2| -3065.006| 3025.699| 3025.721| 3040.697| 15.81785|  17233.7|        1094|    2|\n\n\n:::\n:::\n\n-->\n\n\n## Lab Activity 2\n\n1. Filter to the same (or another) country.\n2. Define a new variable, `log_deaths` = $\\\\(\\log(1 + \\text{ConfirmedDeaths})\\\\)$.\n3. Regress `log_deaths` on `StringencyIndex_Average` using TSLM.\n4. Check if increased stringency is correlated with reduced deaths (i.e., a negative slope).\n\n<!--\n\n### Solution\n\n::: {.cell}\n\n```{.r .cell-code}\n# Filter & transform\nexercise2_data <- oxcgrt %>%\n  filter(CountryName == 'United States') %>%\n  mutate(\n    Date = ymd(Date),\n    log_deaths = log(1 + ConfirmedDeaths)\n  ) %>%\n  as_tsibble(index = Date) %>%\n  drop_na(log_deaths, StringencyIndex_Average)\n\n# Fit TSLM\nex2_model <- exercise2_data %>%\n  model(tslm_ex2 = TSLM(log_deaths ~ StringencyIndex_Average))\n\n# Summaries\nex2_model %>% tidy(tslm_ex2)  %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|.model   |term                    |  estimate| std.error| statistic| p.value|\n|:--------|:-----------------------|---------:|---------:|---------:|-------:|\n|tslm_ex2 |(Intercept)             | 9.3193169| 0.2484414|  37.51112|       0|\n|tslm_ex2 |StringencyIndex_Average | 0.0585671| 0.0047442|  12.34504|       0|\n\n\n:::\n\n```{.r .cell-code}\nex2_model %>% glance(tslm_ex2)  %>% knitr::kable()\n```\n\n::: {.cell-output-display}\n\n\n|.model   | r_squared| adj_r_squared|   sigma2| statistic| p_value| df|   log_lik|      AIC|   AICc|      BIC|       CV| deviance| df.residual| rank|\n|:--------|---------:|-------------:|--------:|---------:|-------:|--:|---------:|--------:|------:|--------:|--------:|--------:|-----------:|----:|\n|tslm_ex2 | 0.1222721|     0.1214698| 9.854598|  152.3999|       0|  2| -2807.946| 2511.578| 2511.6| 2526.577| 9.911232| 10780.93|        1094|    2|\n\n\n:::\n:::\n\n\n-->\n\n",
    "supporting": [
      "activity9_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}