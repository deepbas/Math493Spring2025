---
title: "Activity32"
format: 
  live-html:
    theme:
      light: [lux, theme-light.scss]
      dark: [superhero, theme-dark.scss] 
engine: knitr
toc: true
---

{{< include _extensions/r-wasm/live/_knitr.qmd >}}

```{r}
#| echo: false
# Time Series Essentials, install if needed!
library(feasts)       # Feature extraction & decomposition
library(fable)        # Forecasting models (ARIMA, ETS, etc.)
library(fpp3)         # Tidy time series dataseta
library(astsa)        # Applied statistical TS methods from textbook
library(tseries)      # Unit root tests & TS diagnostics
library(tsibbledata)  # Curated TS datasets
library(quantmod)     # Financial data retrieval
library(tidyquant)    # Financial analysis in tidyverse
library(purrr)        # Functional programming for TS pipelines
library(readr)        # Efficient data import
```


```{webr}
# Prepare data with proper time index
cement <- aus_production %>%
  select(Quarter, Cement) %>%
  as_tsibble(index = Quarter)

# Split into train/test sets
train <- cement %>% filter(year(Quarter) < 2005)
test <- cement %>% filter(year(Quarter) >= 2005)
```

## Fitting Comparable ETS Models

Let's compare some ETS specifications including:

1. Simple exponential smoothing (no trend/seasonality)
2. Holt's linear trend method
3. Holt-Winters seasonal method

```{webr}
ets_models <- train %>%
  model(
    Simple = ETS(Cement ~ error("A") + trend("N") + season("N")),
    Holt = ETS(Cement ~ error("A") + trend("A") + season("N")),
    HW = ETS(Cement ~ error("A") + trend("A") + season("A")),
    HWM = ETS(Cement ~ error("A") + trend("A") + season("M")),
    HWMM = ETS(Cement ~ error("A") + trend("M") + season("M"))
  )
```

## Forecast Evaluation Framework

We'll evaluate using multiple metrics:

- **MSE**: Mean Squared Error (penalizes large errors)
- **MAE**: Mean Absolute Error (more robust)
- **MAPE**: Mean Absolute Percentage Error (scale-independent)
- **MASE**: Mean Absolute Scaled Error (relative to naive forecast)

```{webr}
# Generate forecasts
fc <- ets_models %>% forecast(h = "5 years")
fc %>% tail()

# Calculate accuracy metrics
accuracy_results <- fc %>%
  accuracy(cement) %>%
  select(.model, RMSE, MAE, MAPE, MASE) %>%
  arrange(MASE)

accuracy_table <- fc %>%
  accuracy(test, measures = list(
    MAE = MAE,
    MSE = MSE,
    MAPE = MAPE,
    CRPS = CRPS,
    ACF = ACF1
  ))

accuracy_results %>% inner_join(accuracy_table)
```

## Visual Verification

```{webr}
autoplot(fc, level = NULL) +
  autolayer(cement, color = "black", alpha = 0.3) +
  labs(title = "ETS Model Forecast Comparison",
       subtitle = "Holt-Winters shows closest fit to actual data",
       y = "Cement Production")
```


## Model Diagnostics

We should also check residuals:

```{webr}
ets_models %>% 
  select(HWMM) %>% 
  gg_tsresiduals() +
  labs(title = "Holt-Winters Residual Diagnostics")
```


## Lab Activities

Fit an ETS(A,A,M) and ARIMA(0,1,1) model, then compare their residuals

**Part A:** Fit both models and compare their accuracy using MASE and RMSE  
**Part B:** Analyze residual diagnostics to determine which model handles autocorrelation better  


<details>
<summary><b>Solution</b></summary>

```{webr}
activity1 <- train %>%
  model(
    ETS = ETS(Cement ~ error("A") + trend("A") + season("M")),
    ARIMA = ARIMA(Cement ~ pdq(0,1,1) + PDQ(0,0,0))
  )

activity1 %>%
  forecast(h = 8) %>%
  accuracy(test, measures = list(
    MAE = MAE,
    MSE = MSE,
    MAPE = MAPE,
    CRPS = CRPS,
    ACF = ACF1
    )) 

activity1 %>% select(ETS) %>% 
  gg_tsresiduals()

activity1 %>% select(ARIMA) %>% 
  gg_tsresiduals()

activity1 %>% select(ETS) %>% augment() %>% 
  features(.resid, ~ljung_box(.x, lag = 20))
```

</details>

**Prompt:** "Which model shows better residual properties for supply chain forecasting? Justify using ACF plots and Ljung-Box test statistics."


---

### **Activity 2: Transformation Impact Analysis**

**Part A:** Implement Box-Cox transformation on the Holt-Winters model using $\lambda = 0.2$
**Part B: (Optional)** Evaluate if transformation improves forecast interval coverage at 95% level  


<details>
<summary><b>Solution</b></summary>

```{webr}
lambda <- 0.2 

activity2 <- train %>%
  model(
    Original = ETS(Cement ~ error("A") + trend("A") + season("A")),
    Transformed = ETS(box_cox(Cement, lambda) ~ error("A") + trend("A") + season("A"))
  )

activity2 %>%
  forecast(h = 8) %>%
  accuracy(test, measures = list(
    MAE = MAE,
    MSE = MSE,
    MAPE = MAPE,
    CRPS = CRPS,
    ACF = ACF1)
    ) 


# Prediction interval coverage
activity2_coverage <- activity2 %>%
  forecast(h = 8, level = 95) %>%
  hilo(level = 95) %>%
  unpack_hilo(`95%`) %>%
  as_tibble() %>%
  left_join(test %>% rename(Cement_test = Cement), by = "Quarter") %>%
  mutate(
    # Compare test values to forecast interval
    covered = Cement_test >= `95%_lower` & Cement_test <= `95%_upper`
  ) %>%
  group_by(.model) %>%
  summarise(coverage_rate = mean(covered, na.rm = TRUE) * 100, .groups = "drop")

activity2_coverage
```

</details>


**Prompt:** "Does variance stabilization help maintain prediction interval reliability during demand spikes? 


### **Activity 3: Ensemble Forecasting Strategy**

**Part A:** Create equal-weighted average of ETS and ARIMA forecasts  
**Part B:** Verify if ensemble reduces mean error  


<details>
<summary><b>Solution</b></summary>

```{webr}
activity3 <- train %>%
  model(
    ETS = ETS(Cement),
    ARIMA = ARIMA(Cement)
  ) %>%
  mutate(Ensemble = (ETS + ARIMA)/2)

activity3 %>%
  forecast(h = 8) %>%
  accuracy(test, measures = list(
    MAE = MAE,
    MSE = MSE,
    MAPE = MAPE,
    CRPS = CRPS,
    ACF = ACF1,
    ME = ME
    )
  )
```

</details>


**Prompt:** "When would an ensemble be particularly valuable for cement production planning? Consider both average and worst-case performance."